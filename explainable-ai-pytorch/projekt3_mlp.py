# -*- coding: utf-8 -*-
"""Projekt3_MLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MhzrxYn5ZHD1SvL7dpuO7LJzwusfqKml
"""

!pip install captum

import torch
import torch.nn as nn
import numpy as np
from sklearn.datasets import load_wine, load_iris, load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import Dataset
from captum.attr import IntegratedGradients
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

# --------- Definicja modelu ---------
class SimpleMLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, use_relu=True):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU() if use_relu else nn.Identity()
        self.fc2 = nn.Linear(hidden_dim, output_dim)
    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

# --------- Dataset ---------
class NumpyDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# --------- Przygotowanie danych ---------
def prepare_sklearn_dataset(load_fn, test_size=0.2, random_state=42):
    data = load_fn()
    X_train, X_test, y_train, y_test = train_test_split(
        data.data, data.target, test_size=test_size, random_state=random_state, stratify=data.target
    )
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    return X_train, X_test, y_train, y_test, data.feature_names, data.target_names

# --------- Ładowanie modelu ---------
def load_model(model_class, model_kwargs, path):
    model = model_class(**model_kwargs)
    model.load_state_dict(torch.load(path, map_location='cpu'))
    model.eval()
    return model

# --------- Analiza atrybucji ---------
def analyze_attributions(model, ds_test, y_test, feature_names, target_names, dataset_name, n_examples_per_class=5):
    preds = []
    probs = []
    for x, _ in ds_test:
        with torch.no_grad():
            out = model(x.unsqueeze(0))
            preds.append(out.argmax(dim=1).item())
            probs.append(torch.softmax(out, dim=1).max().item())
    preds = np.array(preds)
    probs = np.array(probs)
    y_test = np.array(y_test)

    # Licz atrybucje IG dla wszystkich przykładów, względem przewidywanej klasy
    ig = IntegratedGradients(model)
    all_attributions = []
    for i, (x, _) in enumerate(ds_test):
        x = x.unsqueeze(0)
        attr = ig.attribute(x, baselines=torch.zeros_like(x), target=int(preds[i]))
        all_attributions.append(attr.detach().cpu().numpy().flatten())
    all_attributions = np.array(all_attributions)  # <-- Zamiana na tablicę NumPy

    # --- Średnie atrybucje dla każdej klasy ---
    print(f"\nŚrednie atrybucje IG dla każdej klasy w zbiorze {dataset_name}:")
    for c in np.unique(y_test):
        class_attr = all_attributions[y_test == c]
        mean_attr = class_attr.mean(axis=0)
        print(f"\nKlasa {target_names[c]}:")
        for fname, val in zip(feature_names, mean_attr):
            print(f"  {fname}: {val:.3f}")
        plt.figure(figsize=(8,3))
        plt.bar(range(len(mean_attr)), mean_attr)
        plt.xticks(range(len(mean_attr)), feature_names, rotation=45, ha='right')
        plt.title(f"{dataset_name} - IG (średnie atrybucje dla klasy {target_names[c]})")
        plt.tight_layout()
        plt.show()

    # --- Przykłady błędnych predykcji ---
    print(f"\nPrzykłady błędnych predykcji w zbiorze {dataset_name}:")
    wrong_indices = np.where(preds != y_test)[0]
    if len(wrong_indices) == 0:
        print("Brak błędnych predykcji na zbiorze testowym.")
    for idx in wrong_indices:
        print(f"Przykład {idx}: Prawdziwa klasa: {target_names[y_test[idx]]}, Predykcja: {target_names[preds[idx]]}, Pewność: {probs[idx]:.3f}")
        attr = all_attributions[idx]
        print("Atrybucje IG:", np.round(attr, 3))
        plt.figure(figsize=(8,3))
        plt.bar(range(len(attr)), attr)
        plt.xticks(range(len(attr)), feature_names, rotation=45, ha='right')
        plt.title(f"{dataset_name} - IG (błędna predykcja, przykład {idx})")
        plt.tight_layout()
        plt.show()

    # --- Porównanie atrybucji dla wielu przykładów z tej samej klasy ---
    print(f"\nPorównanie atrybucji dla {n_examples_per_class} przykładów z każdej klasy w zbiorze {dataset_name}:")
    for c in np.unique(y_test):
        class_indices = np.where(y_test == c)[0][:n_examples_per_class]
        for idx in class_indices:
            print(f"Przykład {idx}: Predykcja: {target_names[preds[idx]]}, Pewność: {probs[idx]:.3f}")
            attr = all_attributions[idx]
            print("Atrybucje IG:", np.round(attr, 3))
            plt.figure(figsize=(8,3))
            plt.bar(range(len(attr)), attr)
            plt.xticks(range(len(attr)), feature_names, rotation=45, ha='right')
            plt.title(f"{dataset_name} - IG (klasa {target_names[c]}, przykład {idx})")
            plt.tight_layout()
            plt.show()

    # --- Zestawienie z wiedzą dziedzinową ---
    print(f"\nZestawienie z wiedzą dziedzinową dla zbioru {dataset_name}:")
    if dataset_name.lower() == "wine":
        print("Literatura: cechy 'alcohol', 'flavanoids', 'proline' są ważne w klasyfikacji win.")
    elif dataset_name.lower() == "iris":
        print("Literatura: cechy 'petal length (cm)', 'petal width (cm)' są kluczowe dla klasyfikacji irysów.")
    elif dataset_name.lower() == "breast cancer":
        print("Literatura: cechy związane z 'mean radius', 'mean texture', 'mean perimeter' są istotne w diagnozie raka piersi.")
    print("Sprawdź, czy te cechy mają wysokie średnie atrybucje IG dla poszczególnych klas.\n")

        # --- Analiza najczęstszych błędów klasyfikacji ---
    print(f"\nMacierz pomyłek dla zbioru {dataset_name}:")
    cm = confusion_matrix(y_test, preds)
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names, cmap="Blues")
    plt.xlabel("Predykcje")
    plt.ylabel("Prawdziwe klasy")
    plt.title(f"Macierz pomyłek - {dataset_name}")
    plt.show()

    # Znajdź najczęściej mylone pary klas (pomijając poprawne klasyfikacje na przekątnej)
    cm_no_diag = cm.copy()
    np.fill_diagonal(cm_no_diag, 0)
    max_misclass = cm_no_diag.max()
    if max_misclass == 0:
        print("Brak błędnych klasyfikacji między różnymi klasami.")
    else:
        print(f"\nNajczęściej mylone klasy w zbiorze {dataset_name}:")
        indices = np.argwhere(cm_no_diag == max_misclass)
        for true_class, pred_class in indices:
            print(f"  Klasa '{target_names[true_class]}' najczęściej błędnie klasyfikowana jako '{target_names[pred_class]}' ({max_misclass} razy)")

# --------- Główna funkcja ---------
if __name__ == "__main__":
    # Wine
    wine_model_path = "mlp_wine.pth"
    wine_kwargs = dict(input_dim=13, hidden_dim=32, output_dim=3)
    X_train, X_test, y_train, y_test, feature_names, target_names = prepare_sklearn_dataset(load_wine)
    ds_test = NumpyDataset(X_test, y_test)
    model = load_model(SimpleMLP, wine_kwargs, wine_model_path)
    analyze_attributions(model, ds_test, y_test, feature_names, target_names, "Wine")

    # Iris
    iris_model_path = "mlp_iris.pth"
    iris_kwargs = dict(input_dim=4, hidden_dim=16, output_dim=3)
    X_train, X_test, y_train, y_test, feature_names, target_names = prepare_sklearn_dataset(load_iris)
    ds_test = NumpyDataset(X_test, y_test)
    model = load_model(SimpleMLP, iris_kwargs, iris_model_path)
    analyze_attributions(model, ds_test, y_test, feature_names, target_names, "Iris")

    # Breast Cancer
    breast_model_path = "mlp_breast_cancer.pth"
    breast_kwargs = dict(input_dim=30, hidden_dim=32, output_dim=2)
    X_train, X_test, y_train, y_test, feature_names, target_names = prepare_sklearn_dataset(load_breast_cancer)
    ds_test = NumpyDataset(X_test, y_test)
    model = load_model(SimpleMLP, breast_kwargs, breast_model_path)
    analyze_attributions(model, ds_test, y_test, feature_names, target_names, "Breast Cancer")

!pip install captum

import torch
import torch.nn as nn
import numpy as np
from sklearn.datasets import load_wine, load_iris, load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import Dataset
from captum.attr import IntegratedGradients
import matplotlib.pyplot as plt

class SimpleMLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, use_relu=True):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU() if use_relu else nn.Identity()
        self.fc2 = nn.Linear(hidden_dim, output_dim)
    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

class NumpyDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

def prepare_sklearn_dataset(load_fn, test_size=0.2, random_state=42):
    data = load_fn()
    X_train, X_test, y_train, y_test = train_test_split(
        data.data, data.target, test_size=test_size, random_state=random_state, stratify=data.target
    )
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    return X_train, X_test, y_train, y_test, data.feature_names, data.target_names

def load_model(model_class, model_kwargs, path):
    model = model_class(**model_kwargs)
    model.load_state_dict(torch.load(path, map_location='cpu'))
    model.eval()
    return model

def explain_local_examples(model, ds_test, y_test, feature_names, target_names, dataset_name, n_examples_per_class=2):
    preds = []
    probs = []
    for x, _ in ds_test:
        with torch.no_grad():
            out = model(x.unsqueeze(0))
            preds.append(out.argmax(dim=1).item())
            probs.append(torch.softmax(out, dim=1).max().item())
    preds = np.array(preds)
    probs = np.array(probs)
    y_test = np.array(y_test)
    ig = IntegratedGradients(model)

    # --- Wybrane przykłady z każdej klasy ---
    print(f"\nLokalne objaśnienia dla wybranych przykładów w zbiorze {dataset_name}:")
    for c in np.unique(y_test):
        class_indices = np.where(y_test == c)[0][:n_examples_per_class]
        for idx in class_indices:
            x, y_true = ds_test[idx]
            y_pred = preds[idx]
            prob = probs[idx]
            attr = ig.attribute(x.unsqueeze(0), baselines=torch.zeros_like(x.unsqueeze(0)), target=int(y_pred))
            attr = attr.detach().cpu().numpy().flatten()
            print(f"\nPrzykład {idx} (klasa prawdziwa: {target_names[y_true]}, predykcja: {target_names[y_pred]}, pewność: {prob:.3f})")
            print("Atrybucje IG:", np.round(attr, 3))
            plt.figure(figsize=(8,3))
            plt.bar(range(len(attr)), attr)
            plt.xticks(range(len(attr)), feature_names, rotation=45, ha='right')
            plt.title(f"{dataset_name} - IG (przykład {idx}, klasa {target_names[y_true]})")
            plt.tight_layout()
            plt.show()

    # --- Przykłady błędnych predykcji ---
    print(f"\nLokalne objaśnienia dla błędnych predykcji w zbiorze {dataset_name}:")
    wrong_indices = np.where(preds != y_test)[0]
    if len(wrong_indices) == 0:
        print("Brak błędnych predykcji na zbiorze testowym.")
    for idx in wrong_indices:
        x, y_true = ds_test[idx]
        y_pred = preds[idx]
        prob = probs[idx]
        attr = ig.attribute(x.unsqueeze(0), baselines=torch.zeros_like(x.unsqueeze(0)), target=int(y_pred))
        attr = attr.detach().cpu().numpy().flatten()
        print(f"\nPrzykład {idx} (klasa prawdziwa: {target_names[y_true]}, predykcja: {target_names[y_pred]}, pewność: {prob:.3f})")
        print("Atrybucje IG:", np.round(attr, 3))
        plt.figure(figsize=(8,3))
        plt.bar(range(len(attr)), attr)
        plt.xticks(range(len(attr)), feature_names, rotation=45, ha='right')
        plt.title(f"{dataset_name} - IG (błędna predykcja, przykład {idx})")
        plt.tight_layout()
        plt.show()

if __name__ == "__main__":
    # Wine
    wine_model_path = "mlp_wine.pth"
    wine_kwargs = dict(input_dim=13, hidden_dim=32, output_dim=3)
    X_train, X_test, y_train, y_test, feature_names, target_names = prepare_sklearn_dataset(load_wine)
    ds_test = NumpyDataset(X_test, y_test)
    model = load_model(SimpleMLP, wine_kwargs, wine_model_path)
    explain_local_examples(model, ds_test, y_test, feature_names, target_names, "Wine")

    # Iris
    iris_model_path = "mlp_iris.pth"
    iris_kwargs = dict(input_dim=4, hidden_dim=16, output_dim=3)
    X_train, X_test, y_train, y_test, feature_names, target_names = prepare_sklearn_dataset(load_iris)
    ds_test = NumpyDataset(X_test, y_test)
    model = load_model(SimpleMLP, iris_kwargs, iris_model_path)
    explain_local_examples(model, ds_test, y_test, feature_names, target_names, "Iris")

    # Breast Cancer
    breast_model_path = "mlp_breast_cancer.pth"
    breast_kwargs = dict(input_dim=30, hidden_dim=32, output_dim=2)
    X_train, X_test, y_train, y_test, feature_names, target_names = prepare_sklearn_dataset(load_breast_cancer)
    ds_test = NumpyDataset(X_test, y_test)
    model = load_model(SimpleMLP, breast_kwargs, breast_model_path)
    explain_local_examples(model, ds_test, y_test, feature_names, target_names, "Breast Cancer")

import os
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from torchvision.datasets import MNIST
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
from captum.attr import IntegratedGradients, Saliency, GradientShap, Occlusion

# --------- Model ---------
class SimpleMLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, use_relu=True):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU() if use_relu else nn.Identity()
        self.fc2 = nn.Linear(hidden_dim, output_dim)
    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

# --------- Dataset wrapper ---------
class NumpyDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# --------- Przygotowanie danych MNIST (784 cechy) ---------
def prepare_mnist_784():
    transform = transforms.ToTensor()
    mnist_train = MNIST(root='.', train=True, download=True, transform=transform)
    mnist_test = MNIST(root='.', train=False, download=True, transform=transform)
    X_train = mnist_train.data.numpy().reshape(-1, 28*28) / 255.0
    y_train = mnist_train.targets.numpy()
    X_test = mnist_test.data.numpy().reshape(-1, 28*28) / 255.0
    y_test = mnist_test.targets.numpy()
    return X_train, X_test, y_train, y_test

# --------- Przygotowanie danych MNIST (quadrants) ---------
def prepare_mnist_quadrants():
    transform = transforms.ToTensor()
    mnist_train = MNIST(root='.', train=True, download=True, transform=transform)
    mnist_test = MNIST(root='.', train=False, download=True, transform=transform)
    def quadrants(img):
        # Suma pikseli w 4 ćwiartkach
        q1 = img[:14, :14].sum()
        q2 = img[:14, 14:].sum()
        q3 = img[14:, :14].sum()
        q4 = img[14:, 14:].sum()
        return np.array([q1, q2, q3, q4])
    X_train = np.stack([quadrants(img) for img, _ in mnist_train])
    y_train = mnist_train.targets.numpy()
    X_test = np.stack([quadrants(img) for img, _ in mnist_test])
    y_test = mnist_test.targets.numpy()
    return X_train, X_test, y_train, y_test

# --------- Przygotowanie danych MNIST (PCA) ---------
def prepare_mnist_pca(n_components=2):
    from sklearn.decomposition import PCA
    transform = transforms.ToTensor()
    mnist_train = MNIST(root='.', train=True, download=True, transform=transform)
    mnist_test = MNIST(root='.', train=False, download=True, transform=transform)
    X_train = mnist_train.data.numpy().reshape(-1, 28*28) / 255.0
    y_train = mnist_train.targets.numpy()
    X_test = mnist_test.data.numpy().reshape(-1, 28*28) / 255.0
    y_test = mnist_test.targets.numpy()
    pca = PCA(n_components=n_components)
    X_train_pca = pca.fit_transform(X_train)
    X_test_pca = pca.transform(X_test)
    return X_train_pca, X_test_pca, y_train, y_test

# --------- Załaduj model ---------
def load_model(model_class, model_kwargs, path, device='cpu'):
    model = model_class(**model_kwargs)
    model.load_state_dict(torch.load(path, map_location=device))
    model.to(device)
    model.eval()
    return model

# --------- Wizualizacja atrybucji jako obrazka ---------
def show_attribution_map(attributions, img, title, cmap='seismic'):
    plt.figure(figsize=(8,3))
    plt.subplot(1,2,1)
    plt.imshow(img.reshape(28,28), cmap='gray')
    plt.title("Obraz wejściowy")
    plt.axis('off')
    plt.subplot(1,2,2)
    plt.imshow(attributions.reshape(28,28), cmap=cmap)
    plt.title(title)
    plt.axis('off')
    plt.tight_layout()
    plt.show()

# --------- Lokalna analiza dla modelu 784 cechy ---------
def explain_local_examples_mnist_784(model, X_test, y_test, device, example_indices):
    model.eval()
    X = torch.tensor(X_test, dtype=torch.float32).to(device)
    y = torch.tensor(y_test, dtype=torch.long).to(device)
    ig = IntegratedGradients(model)
    sal = Saliency(model)
    gshap = GradientShap(model)
    occ = Occlusion(model)
    for idx in example_indices:
        x = X[idx].unsqueeze(0)
        y_true = y[idx].item()
        with torch.no_grad():
            logits = model(x)
            y_pred = logits.argmax(dim=1).item()
            prob = torch.softmax(logits, dim=1)[0, y_pred].item()
        print(f"\n[MLP784] Przykład {idx}: Prawdziwa klasa: {y_true}, Predykcja: {y_pred}, Pewność: {prob:.3f}")

        # Integrated Gradients
        attr_ig = ig.attribute(x, baselines=torch.zeros_like(x), target=y_pred).cpu().numpy().reshape(-1)
        show_attribution_map(attr_ig, x.cpu().numpy().reshape(-1), f"Integrated Gradients (klasa {y_pred})")

        # Saliency
        attr_sal = sal.attribute(x, target=y_pred).cpu().numpy().reshape(-1)
        show_attribution_map(attr_sal, x.cpu().numpy().reshape(-1), f"Saliency (klasa {y_pred})")

        # GradientShap
        rand_baseline = x + 0.1*torch.randn_like(x)
        attr_gshap = gshap.attribute(x, baselines=rand_baseline, target=y_pred).cpu().numpy().reshape(-1)
        show_attribution_map(attr_gshap, x.cpu().numpy().reshape(-1), f"GradientShap (klasa {y_pred})")

        # Occlusion (dla 1D wejścia 784 elementy)
        attr_occ = occ.attribute(x, strides=(28,), sliding_window_shapes=(196,), target=y_pred).cpu().numpy().reshape(-1)
        show_attribution_map(attr_occ, x.cpu().numpy().reshape(-1), f"Occlusion (klasa {y_pred})")

# --------- Lokalna analiza dla modelu quadrants ---------
def explain_local_examples_mnist_quadrants(model, X_test, y_test, device, example_indices):
    model.eval()
    X = torch.tensor(X_test, dtype=torch.float32).to(device)
    y = torch.tensor(y_test, dtype=torch.long).to(device)
    ig = IntegratedGradients(model)
    sal = Saliency(model)
    gshap = GradientShap(model)
    for idx in example_indices:
        x = X[idx].unsqueeze(0)
        y_true = y[idx].item()
        with torch.no_grad():
            logits = model(x)
            y_pred = logits.argmax(dim=1).item()
            prob = torch.softmax(logits, dim=1)[0, y_pred].item()
        print(f"\n[MLP_quadrants] Przykład {idx}: Prawdziwa klasa: {y_true}, Predykcja: {y_pred}, Pewność: {prob:.3f}")

        attr_ig = ig.attribute(x, baselines=torch.zeros_like(x), target=y_pred).cpu().numpy().flatten()
        attr_sal = sal.attribute(x, target=y_pred).cpu().numpy().flatten()
        rand_baseline = x + 0.1*torch.randn_like(x)
        attr_gshap = gshap.attribute(x, baselines=rand_baseline, target=y_pred).cpu().numpy().flatten()

        plt.figure(figsize=(8,2))
        plt.bar(np.arange(4)-0.2, attr_ig, width=0.2, label="Integrated Gradients")
        plt.bar(np.arange(4), attr_sal, width=0.2, label="Saliency")
        plt.bar(np.arange(4)+0.2, attr_gshap, width=0.2, label="GradientShap")
        plt.xticks(range(4), ['Q1','Q2','Q3','Q4'])
        plt.title(f"Atrybucje (przykład {idx}, klasa {y_true})")
        plt.legend()
        plt.tight_layout()
        plt.show()

# --------- Lokalna analiza dla modelu PCA ---------
def explain_local_examples_mnist_pca(model, X_test, y_test, device, example_indices):
    model.eval()
    X = torch.tensor(X_test, dtype=torch.float32).to(device)
    y = torch.tensor(y_test, dtype=torch.long).to(device)
    ig = IntegratedGradients(model)
    sal = Saliency(model)
    gshap = GradientShap(model)
    for idx in example_indices:
        x = X[idx].unsqueeze(0)
        y_true = y[idx].item()
        with torch.no_grad():
            logits = model(x)
            y_pred = logits.argmax(dim=1).item()
            prob = torch.softmax(logits, dim=1)[0, y_pred].item()
        print(f"\n[MLP_PCA] Przykład {idx}: Prawdziwa klasa: {y_true}, Predykcja: {y_pred}, Pewność: {prob:.3f}")

        attr_ig = ig.attribute(x, baselines=torch.zeros_like(x), target=y_pred).cpu().numpy().flatten()
        attr_sal = sal.attribute(x, target=y_pred).cpu().numpy().flatten()
        rand_baseline = x + 0.1*torch.randn_like(x)
        attr_gshap = gshap.attribute(x, baselines=rand_baseline, target=y_pred).cpu().numpy().flatten()

        plt.figure(figsize=(8,2))
        plt.bar(np.arange(len(attr_ig))-0.2, attr_ig, width=0.2, label="Integrated Gradients")
        plt.bar(np.arange(len(attr_sal)), attr_sal, width=0.2, label="Saliency")
        plt.bar(np.arange(len(attr_gshap))+0.2, attr_gshap, width=0.2, label="GradientShap")
        plt.xticks(range(len(attr_ig)), [f"PC{i+1}" for i in range(len(attr_ig))])
        plt.title(f"Atrybucje (przykład {idx}, klasa {y_true})")
        plt.legend()
        plt.tight_layout()
        plt.show()

# --------- Wybór najciekawszych przypadków ---------
def find_interesting_examples(model, X, y, device='cpu', n=3, min_threshold=0.8, step=0.05):
    model.eval()
    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)
    y_tensor = torch.tensor(y, dtype=torch.long).to(device)
    with torch.no_grad():
        out = model(X_tensor)
        probs = torch.softmax(out, dim=1)
        preds = out.argmax(dim=1)
    threshold = 0.99
    confident_correct = []
    # Automatyczne obniżanie progu, jeśli nie ma wystarczająco przypadków
    while threshold >= min_threshold:
        confident_correct = ((preds == y_tensor) & (probs.max(dim=1).values > threshold)).nonzero(as_tuple=True)[0][:n].tolist()
        if len(confident_correct) >= n:
            break
        threshold -= step
    # Jeśli nadal nie znalazło, weź tyle ile jest
    if len(confident_correct) == 0:
        confident_correct = ((preds == y_tensor) & (probs.max(dim=1).values > min_threshold)).nonzero(as_tuple=True)[0][:n].tolist()
    wrong = (preds != y_tensor).nonzero(as_tuple=True)[0][:n].tolist()
    uncertain = (probs.max(dim=1).values < 0.6).nonzero(as_tuple=True)[0][:n].tolist()
    print(f"Użyty próg pewności dla confident_correct: {threshold:.2f} (znaleziono {len(confident_correct)} przykładów)")
    return confident_correct, wrong, uncertain



# --------- GŁÓWNY PIPELINE ---------
if __name__ == "__main__":
    device = 'cpu'

    # --- MNIST 784D ---
    print("\n=== Analiza modelu: mlp_mnist_784.pth ===")
    X_train_784, X_test_784, y_train_784, y_test_784 = prepare_mnist_784()
    model_784 = load_model(
        SimpleMLP,
        {'input_dim': 784, 'hidden_dim': 128, 'output_dim': 10, 'use_relu': True},
        'mlp_mnist_784.pth',
        device=device
    )
    conf, wrong, uncer = find_interesting_examples(model_784, X_test_784, y_test_784, device)
    print(f"Najpewniejsze poprawne: {conf}")
    print(f"Błędne: {wrong}")
    print(f"Niepewne: {uncer}")
    print("\n--- Najpewniejsze poprawne ---")
    explain_local_examples_mnist_784(model_784, X_test_784, y_test_784, device, conf)
    print("\n--- Błędne ---")
    explain_local_examples_mnist_784(model_784, X_test_784, y_test_784, device, wrong)
    print("\n--- Niepewne ---")
    explain_local_examples_mnist_784(model_784, X_test_784, y_test_784, device, uncer)

    # --- MNIST PCA 2D ---
    print("\n=== Analiza modelu: mlp_mnist_pca_2d.pth ===")
    X_train_pca, X_test_pca, y_train_pca, y_test_pca = prepare_mnist_pca(n_components=2)
    model_pca = load_model(
        SimpleMLP,
        {'input_dim': 2, 'hidden_dim': 32, 'output_dim': 10, 'use_relu': True},
        'mlp_mnist_pca_2d.pth',
        device=device
    )
    conf, wrong, uncer = find_interesting_examples(model_pca, X_test_pca, y_test_pca, device)
    print(f"Najpewniejsze poprawne: {conf}")
    print(f"Błędne: {wrong}")
    print(f"Niepewne: {uncer}")
    print("\n--- Najpewniejsze poprawne ---")
    explain_local_examples_mnist_pca(model_pca, X_test_pca, y_test_pca, device, conf)
    print("\n--- Błędne ---")
    explain_local_examples_mnist_pca(model_pca, X_test_pca, y_test_pca, device, wrong)
    print("\n--- Niepewne ---")
    explain_local_examples_mnist_pca(model_pca, X_test_pca, y_test_pca, device, uncer)

    # --- MNIST quadrants 4D ---
    print("\n=== Analiza modelu: mlp_mnist_4d_quad.pth ===")
    X_train_quad, X_test_quad, y_train_quad, y_test_quad = prepare_mnist_quadrants()
    model_quad = load_model(
        SimpleMLP,
        {'input_dim': 4, 'hidden_dim': 64, 'output_dim': 10, 'use_relu': True},
        'mlp_mnist_4d_quad.pth',
        device=device
    )
    conf, wrong, uncer = find_interesting_examples(model_quad, X_test_quad, y_test_quad, device)
    print(f"Najpewniejsze poprawne: {conf}")
    print(f"Błędne: {wrong}")
    print(f"Niepewne: {uncer}")
    print("\n--- Najpewniejsze poprawne ---")
    explain_local_examples_mnist_quadrants(model_quad, X_test_quad, y_test_quad, device, conf)
    print("\n--- Błędne ---")
    explain_local_examples_mnist_quadrants(model_quad, X_test_quad, y_test_quad, device, wrong)
    print("\n--- Niepewne ---")
    explain_local_examples_mnist_quadrants(model_quad, X_test_quad, y_test_quad, device, uncer)

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def evaluate_model(model, X, y, device='cpu'):
    model.eval()
    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)
    y_tensor = torch.tensor(y, dtype=torch.long).to(device)
    with torch.no_grad():
        outputs = model(X_tensor)
        preds = outputs.argmax(dim=1).cpu().numpy()
    y_true = y_tensor.cpu().numpy()
    acc = accuracy_score(y_true, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(y_true, preds, average='weighted', zero_division=0)
    print(f"Accuracy:  {acc:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall:    {recall:.4f}")
    print(f"F1-score:  {f1:.4f}")
    return acc, precision, recall, f1

print("\n=== Ocena skuteczności modelu mlp_mnist_784.pth ===")
evaluate_model(model_784, X_test_784, y_test_784, device=device)

print("\n=== Ocena skuteczności modelu mlp_mnist_pca_2d.pth ===")
evaluate_model(model_pca, X_test_pca, y_test_pca, device=device)

print("\n=== Ocena skuteczności modelu mlp_mnist_4d_quad.pth ===")
evaluate_model(model_quad, X_test_quad, y_test_quad, device=device)

def summarize_global_attributions_pca(model, X_test, y_test, device):
    model.eval()
    X = torch.tensor(X_test, dtype=torch.float32).to(device)
    y = torch.tensor(y_test, dtype=torch.long).to(device)

    ig = IntegratedGradients(model)
    sal = Saliency(model)
    gshap = GradientShap(model)

    # Uzyskaj predykcje modelu
    with torch.no_grad():
        logits = model(X)
        preds = logits.argmax(dim=1)

    # --- Integrated Gradients ---
    attr_ig = ig.attribute(X, baselines=torch.zeros_like(X), target=preds).cpu().numpy()
    mean_ig = np.mean(np.abs(attr_ig), axis=0)

    # --- Saliency ---
    attr_sal = sal.attribute(X, target=preds).cpu().numpy()
    mean_sal = np.mean(np.abs(attr_sal), axis=0)

    # --- GradientShap ---
    rand_baseline = X + 0.1 * torch.randn_like(X)
    attr_gshap = gshap.attribute(X, baselines=rand_baseline, target=preds).cpu().numpy()
    mean_gshap = np.mean(np.abs(attr_gshap), axis=0)

    labels = ['PC1', 'PC2']
    x = np.arange(len(labels))

    plt.figure(figsize=(8, 3))
    plt.bar(x - 0.2, mean_ig, width=0.2, label='Integrated Gradients')
    plt.bar(x, mean_sal, width=0.2, label='Saliency')
    plt.bar(x + 0.2, mean_gshap, width=0.2, label='GradientShap')
    plt.xticks(x, labels)
    plt.ylabel("Średnia wartość |atrybucji|")
    plt.title("Globalna istotność cech PCA")
    plt.legend()
    plt.tight_layout()
    plt.show()


summarize_global_attributions_pca(model_pca, X_test_pca, y_test_pca, device)

def summarize_global_attributions_quadrants(model, X_test, y_test, device):
    model.eval()
    X = torch.tensor(X_test, dtype=torch.float32).to(device)
    y = torch.tensor(y_test, dtype=torch.long).to(device)

    ig = IntegratedGradients(model)
    sal = Saliency(model)
    gshap = GradientShap(model)

    with torch.no_grad():
        logits = model(X)
        preds = logits.argmax(dim=1)

    # Integrated Gradients
    attr_ig = ig.attribute(X, baselines=torch.zeros_like(X), target=preds).cpu().numpy()
    mean_ig = np.mean(np.abs(attr_ig), axis=0)

    # Saliency
    attr_sal = sal.attribute(X, target=preds).cpu().numpy()
    mean_sal = np.mean(np.abs(attr_sal), axis=0)

    # GradientShap
    rand_baseline = X + 0.1 * torch.randn_like(X)
    attr_gshap = gshap.attribute(X, baselines=rand_baseline, target=preds).cpu().numpy()
    mean_gshap = np.mean(np.abs(attr_gshap), axis=0)

    labels = ['Q1', 'Q2', 'Q3', 'Q4']
    x = np.arange(len(labels))

    plt.figure(figsize=(8, 3))
    plt.bar(x - 0.2, mean_ig, width=0.2, label='Integrated Gradients')
    plt.bar(x, mean_sal, width=0.2, label='Saliency')
    plt.bar(x + 0.2, mean_gshap, width=0.2, label='GradientShap')
    plt.xticks(x, labels)
    plt.ylabel("Średnia wartość |atrybucji|")
    plt.title("Globalna istotność cech (quadrants)")
    plt.legend()
    plt.tight_layout()
    plt.show()

summarize_global_attributions_quadrants(model_quad, X_test_quad, y_test_quad, device)