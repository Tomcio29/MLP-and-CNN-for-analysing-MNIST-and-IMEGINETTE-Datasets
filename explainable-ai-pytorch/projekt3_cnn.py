# -*- coding: utf-8 -*-
"""Projekt3_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s4baFn70T-fwc2qoeMWv0IJxMbMYz-zg
"""

# ==================== XAI CNN ANALYSIS FOR MNIST & IMAGENETTE (Colab-ready) ====================
!pip install captum

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torchvision.datasets import MNIST, Imagenette
from torchvision import transforms
from torchvision.transforms import ToTensor, Normalize, Compose, RandomRotation, RandomHorizontalFlip, RandomCrop, Resize
from captum.attr import IntegratedGradients, Saliency, GradientShap, Occlusion
from torch.utils.data import DataLoader

# --- MODELE CNN ---
class SimpleCNN_MNIST(nn.Module):
    def __init__(self, out_features=128, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 16, 3, 1)
        self.conv2 = nn.Conv2d(16, 32, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(32*5*5, out_features)
        self.fc2 = nn.Linear(out_features, num_classes)
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = F.relu(self.fc1(x))
        out = self.fc2(features)
        return out, features

class SimpleCNN_Imagenette(nn.Module):
    def __init__(self, out_features=128, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, 1)
        self.conv2 = nn.Conv2d(16, 32, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(32*14*14, out_features)
        self.fc2 = nn.Linear(out_features, num_classes)
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = F.relu(self.fc1(x))
        out = self.fc2(features)
        return out, features


# --- SPLIT DATA ---
device = 'cuda' if torch.cuda.is_available() else 'cpu'
batch_size = 64

# --- MNIST ---
mnist_transform = Compose([
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])
mnist_test = MNIST(root='./data', train=False, download=True, transform=mnist_transform)
mnist_test_loader = DataLoader(mnist_test, batch_size=batch_size)


# --- Imagenette ---
imagenette_transform = Compose([
    Resize((64, 64)),
    ToTensor(),
    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
imagenette_test = Imagenette(root='./data', split='val', size='160px', download=True, transform=imagenette_transform)
imagenette_test_loader = DataLoader(imagenette_test, batch_size=batch_size)
class_names = imagenette_test.classes


# --- ŁADOWANIE MODELU ---
def load_model(model_class, model_kwargs, path, device='cpu'):
    model = model_class(**model_kwargs)
    model.load_state_dict(torch.load(path, map_location=device))
    model.to(device)
    model.eval()
    return model

# --- PRZYGOTOWANIE DANYCH ---
def get_all_from_loader(loader):
    X_list, y_list = [], []
    for x, y in loader:
        X_list.append(x)
        y_list.append(y)
    X = torch.cat(X_list, dim=0)
    y = torch.cat(y_list, dim=0)
    return X, y

# --- WIZUALIZACJA MAP ATRUBUCJI ---
def show_attribution_map(attributions, img, title, cmap='seismic'):
    img = img.squeeze().cpu().numpy()
    attr = attributions.squeeze().cpu().numpy()
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1)
    if img.ndim == 2:
        plt.imshow(img, cmap='gray')
    else:
        plt.imshow(np.transpose(img, (1,2,0)))
    plt.title("Obraz wejściowy")
    plt.axis('off')
    plt.subplot(1,2,2)
    if attr.ndim == 2:
        plt.imshow(attr, cmap=cmap)
    else:
        plt.imshow(attr.sum(0), cmap=cmap)
    plt.title(title)
    plt.axis('off')
    plt.tight_layout()
    plt.show()

def find_interesting_examples(model, X, y, device, n=5, min_threshold=0.8, step=0.05):
    model.eval()
    with torch.no_grad():
        out, _ = model(X.to(device))
        probs = torch.softmax(out, dim=1)
        preds = out.argmax(dim=1)

    threshold = 0.99
    confident_correct = []
    # Szukaj poprawnych i pewnych
    while threshold >= min_threshold:
        confident_correct = ((preds == y.to(device)) & (probs.max(dim=1).values > threshold)).nonzero(as_tuple=True)[0].tolist()
        if len(confident_correct) >= n:
            break
        threshold -= step

    # Jeśli nadal za mało, uzupełnij poprawnymi predykcjami o niższej pewności
    if len(confident_correct) < n:
        all_correct = (preds == y.to(device)).nonzero(as_tuple=True)[0].tolist()
        for idx in all_correct:
            if idx not in confident_correct:
                confident_correct.append(idx)
            if len(confident_correct) == n:
                break

    # Błędne predykcje, pomijając confident_correct
    wrong_all = (preds != y.to(device)).nonzero(as_tuple=True)[0].tolist()
    wrong = [idx for idx in wrong_all if idx not in confident_correct][:n]

    # Niepewne predykcje, pomijając confident_correct i wrong
    uncertain_all = (probs.max(dim=1).values < 0.6).nonzero(as_tuple=True)[0].tolist()
    uncertain = [idx for idx in uncertain_all if idx not in confident_correct and idx not in wrong][:n]

    print(f"Użyty próg pewności dla confident_correct: {threshold:.2f} (znaleziono {len(confident_correct)} przykładów)")
    return confident_correct[:n], wrong[:n], uncertain[:n]

def find_interesting_examples_diverse(model, X, y, device, n=5, min_threshold=0.8, step=0.05):
    model.eval()
    with torch.no_grad():
        out, _ = model(X.to(device))
        probs = torch.softmax(out, dim=1)
        preds = out.argmax(dim=1)

    threshold = 0.99
    confident_correct = []
    while threshold >= min_threshold:
        candidates = ((preds == y.to(device)) & (probs.max(dim=1).values > threshold)).nonzero(as_tuple=True)[0].tolist()
        if len(candidates) >= n * 10:
            break
        threshold -= step

    if len(candidates) < n * 10:
        all_correct = (preds == y.to(device)).nonzero(as_tuple=True)[0].tolist()
        candidates.extend([i for i in all_correct if i not in candidates])

    # wybierz różne klasy (po 1 przykładzie z klasy)
    confident_correct_diverse = []
    seen_classes = set()
    for i in candidates:
        cls = y[i].item()
        if cls not in seen_classes:
            confident_correct_diverse.append(i)
            seen_classes.add(cls)
        if len(confident_correct_diverse) == n:
            break

    # analogicznie dla błędnych
    wrong_all = (preds != y.to(device)).nonzero(as_tuple=True)[0].tolist()
    wrong_diverse = []
    seen_classes = set()
    for i in wrong_all:
        cls = y[i].item()
        if cls not in seen_classes:
            wrong_diverse.append(i)
            seen_classes.add(cls)
        if len(wrong_diverse) == n:
            break

    # analogicznie dla niepewnych
    uncertain_all = (probs.max(dim=1).values < 0.6).nonzero(as_tuple=True)[0].tolist()
    uncertain_diverse = []
    seen_classes = set()
    for i in uncertain_all:
        cls = y[i].item()
        if cls not in seen_classes:
            uncertain_diverse.append(i)
            seen_classes.add(cls)
        if len(uncertain_diverse) == n:
            break

    return confident_correct_diverse, wrong_diverse, uncertain_diverse


# --- ANALIZA XAI DLA CNN ---
def explain_cnn_examples(model, X, y, device, class_names=None, example_indices=[0,1,2]):
    ig = IntegratedGradients(lambda x: model(x)[0])
    sal = Saliency(lambda x: model(x)[0])
    gshap = GradientShap(lambda x: model(x)[0])
    occ = Occlusion(lambda x: model(x)[0])

    X = X.to(device)
    y = y.to(device)
    for idx in example_indices:
        x = X[idx].unsqueeze(0)
        y_true = y[idx].item()
        with torch.no_grad():
            out, _ = model(x)
            y_pred = out.argmax(dim=1).item()
            prob = torch.softmax(out, dim=1)[0, y_pred].item()
        cname = class_names[y_true] if class_names else str(y_true)
        print(f"\nPrzykład {idx}: Prawdziwa klasa: {cname}, Predykcja: {y_pred}, Pewność: {prob:.3f}")

        # Integrated Gradients
        attr_ig = ig.attribute(x, baselines=torch.zeros_like(x), target=y_pred)
        show_attribution_map(attr_ig, x[0], f"Integrated Gradients (klasa {y_pred})")

        # Saliency
        attr_sal = sal.attribute(x, target=y_pred)
        show_attribution_map(attr_sal, x[0], f"Saliency (klasa {y_pred})")

        # GradientShap
        rand_baseline = x + 0.1*torch.randn_like(x)
        attr_gshap = gshap.attribute(x, baselines=rand_baseline, target=y_pred)
        show_attribution_map(attr_gshap, x[0], f"GradientShap (klasa {y_pred})")

        # Occlusion (napraw stride!)
        window_shape = (1,7,7) if x.shape[1]==1 else (3,7,7)
        stride_shape = window_shape
        attr_occ = occ.attribute(x, strides=stride_shape, sliding_window_shapes=window_shape, target=y_pred)
        show_attribution_map(attr_occ, x[0], f"Occlusion (klasa {y_pred})")


# ==================== GŁÓWNY PIPELINE ====================
if __name__ == "__main__":
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    # --- Pobierz wszystkie dane testowe ---
    X_mnist, y_mnist = get_all_from_loader(mnist_test_loader)
    X_img, y_img = get_all_from_loader(imagenette_test_loader)

    # --- Załaduj modele ---
    best_params_simplecnn = {'out_features': 256}
    best_model_path_simplecnn = 'best_SimpleCNN_MNIST.pt'
    model_mnist = load_model(SimpleCNN_MNIST, {'out_features': 256, 'num_classes': 10}, best_model_path_simplecnn, device)
    model_mnist.eval()

    best_params_simplecnn_img = {'out_features': 64}
    best_model_path_simplecnn_img = 'best_SimpleCNN_Imagenette.pt'
    model_img = load_model(SimpleCNN_Imagenette, {'out_features': 64, 'num_classes': 10}, best_model_path_simplecnn_img, device)
    model_img.eval()

    # --- Wybierz przykłady do XAI ---
    conf_mnist, wrong_mnist, uncer_mnist = find_interesting_examples_diverse(model_mnist, X_mnist, y_mnist, device, n=5)
    conf_img, wrong_img, uncer_img = find_interesting_examples_diverse(model_img, X_img, y_img, device, n=5)

    print(f"MNIST - Najpewniejsze poprawne: {conf_mnist}\nBłędne: {wrong_mnist}\nNiepewne: {uncer_mnist}")
    print(f"Imagenette - Najpewniejsze poprawne: {conf_img}\nBłędne: {wrong_img}\nNiepewne: {uncer_img}")

    # --- Analiza XAI ---
    explain_cnn_examples(model_mnist, X_mnist, y_mnist, device, example_indices=conf_mnist+wrong_mnist+uncer_mnist)
    explain_cnn_examples(model_img, X_img, y_img, device, class_names=class_names, example_indices=conf_img+wrong_img+uncer_img)

with torch.no_grad():
    out, _ = model_img(X_img.to(device))
    preds = out.argmax(dim=1).cpu().numpy()
    import numpy as np
    unique, counts = np.unique(preds, return_counts=True)
    print("Predykcje modelu:", dict(zip(unique, counts)))
acc = (preds == y_img.numpy()).mean()
print(f"Test accuracy: {acc:.3f}")

def print_true_class_distribution(indices, y, class_names):
    classes = y[indices].cpu().numpy()
    unique, counts = np.unique(classes, return_counts=True)
    dist = {class_names[u]: c for u, c in zip(unique, counts)}
    print(dist)

unique, counts = np.unique(y_img.numpy(), return_counts=True)
for u, c in zip(unique, counts):
    print(f"Klasa {class_names[u][0]}: {c} przykładów")

with torch.no_grad():
    out, _ = model_mnist(X_mnist.to(device))
    preds_mnist = out.argmax(dim=1).cpu().numpy()
    unique_mnist, counts_mnist = np.unique(preds_mnist, return_counts=True)
    print("Predykcje modelu MNIST:", dict(zip(unique_mnist, counts_mnist)))

acc_mnist = (preds_mnist == y_mnist.numpy()).mean()
print(f"Test accuracy MNIST: {acc_mnist:.3f}")

import numpy as np

def per_class_accuracy(model, X, y, device, class_names):
    model.eval()
    with torch.no_grad():
        out, _ = model(X.to(device))
        preds = out.argmax(dim=1).cpu().numpy()
        true = y.cpu().numpy()

    unique_classes = np.unique(true)
    accuracies = {}
    for cls in unique_classes:
        cls_mask = (true == cls)
        cls_correct = np.sum(preds[cls_mask] == true[cls_mask])
        cls_total = np.sum(cls_mask)
        acc = cls_correct / cls_total if cls_total > 0 else 0.0
        class_name = class_names[cls][0] if class_names else str(cls)
        accuracies[class_name] = acc
        print(f"Klasa {class_name}: {acc:.3f} ({cls_correct}/{cls_total})")

    # Klasa z najlepszą dokładnością
    best_class = max(accuracies, key=accuracies.get)
    print(f"\nNajlepsza skuteczność dla klasy: {best_class} ({accuracies[best_class]:.3f})")

    return accuracies

# Przykład użycia:
accuracies = per_class_accuracy(model_img, X_img, y_img, device, class_names)
print(accuracies)