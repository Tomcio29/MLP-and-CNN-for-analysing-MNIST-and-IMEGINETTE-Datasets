# -*- coding: utf-8 -*-
"""projekt2.2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ogZiUqtziVPc4sEi7yMeDATsCOcacnOz
"""

# Version 1 Part 1
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset, random_split
from torchvision import datasets, transforms
from torchvision.datasets import MNIST, Imagenette
from torchvision.transforms import ToTensor, Normalize, Compose, RandomRotation, RandomHorizontalFlip, RandomCrop, Resize
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
import random
import copy

def set_seed(seed=42):
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)

set_seed()

# --- TRANSFORMACJE ---
mnist_transform = Compose([
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])

mnist_aug1 = Compose([
    RandomRotation(10),
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])

mnist_aug2 = Compose([
    RandomRotation(20),
    RandomCrop(28, padding=2),
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])

imagenette_transform = Compose([
    Resize((64, 64)),
    ToTensor(),
    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

imagenette_aug1 = Compose([
    Resize((64, 64)),
    RandomHorizontalFlip(),
    RandomRotation(15),
    ToTensor(),
    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

imagenette_aug2 = Compose([
    Resize((64, 64)),
    RandomHorizontalFlip(),
    RandomRotation(30),
    RandomCrop(64, padding=8),
    ToTensor(),
    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# --- DANE ---
mnist_train = MNIST(root='./data', train=True, download=True, transform=mnist_transform)
mnist_test = MNIST(root='./data', train=False, download=True, transform=mnist_transform)

imagenette_train = Imagenette(root='./data', split='train', size='160px', download=True, transform=imagenette_transform)
imagenette_test = Imagenette(root='./data', split='val', size='160px', download=True, transform=imagenette_transform)

# --- MODELE DLA MNIST (1 kanał) ---
class SimpleCNN_MNIST(nn.Module):
    def __init__(self, out_features=128, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 16, 3, 1)
        self.conv2 = nn.Conv2d(16, 32, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(32*5*5, out_features)
        self.fc2 = nn.Linear(out_features, num_classes)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = F.relu(self.fc1(x))
        out = self.fc2(features)
        return out, features

class TwoFeatureCNN_MNIST(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 8, 3, 1)
        self.conv2 = nn.Conv2d(8, 16, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(16*5*5, 2)
        self.fc2 = nn.Linear(2, num_classes)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = self.fc1(x)
        out = self.fc2(features)
        return out, features

# --- MODELE DLA IMAGENETTE (3 kanały) ---
class SimpleCNN_Imagenette(nn.Module):
    def __init__(self, out_features=128, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, 1)
        self.conv2 = nn.Conv2d(16, 32, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        # 64x64 -> 62x62 -> 31x31 -> 29x29 -> 14x14
        self.fc1 = nn.Linear(32*14*14, out_features)
        self.fc2 = nn.Linear(out_features, num_classes)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = F.relu(self.fc1(x))
        out = self.fc2(features)
        return out, features

class TwoFeatureCNN_Imagenette(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 8, 3, 1)
        self.conv2 = nn.Conv2d(8, 16, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(16*14*14, 2)
        self.fc2 = nn.Linear(2, num_classes)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = self.fc1(x)
        out = self.fc2(features)
        return out, features

# --- NARZĘDZIA ---
def train_model(model, train_loader, val_loader, epochs=10, lr=0.001, device='cuda'):
    model = model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()
    train_acc, val_acc = [], []
    best_val_acc = 0
    best_state = None
    for epoch in range(epochs):
        model.train()
        correct = 0
        total = 0
        for x, y in train_loader:
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            outputs, _ = model(x)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()
            _, preds = torch.max(outputs, 1)
            correct += (preds == y).sum().item()
            total += y.size(0)
        train_acc.append(correct/total)
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for x, y in val_loader:
                x, y = x.to(device), y.to(device)
                outputs, _ = model(x)
                _, preds = torch.max(outputs, 1)
                correct += (preds == y).sum().item()
                total += y.size(0)
        val_acc.append(correct/total)
        if val_acc[-1] > best_val_acc:
            best_val_acc = val_acc[-1]
            best_state = copy.deepcopy(model.state_dict())
        print(f"Epoch {epoch+1}: Train acc={train_acc[-1]:.3f}, Val acc={val_acc[-1]:.3f}")
    return train_acc, val_acc, best_state, best_val_acc

def get_predictions(model, loader, device='cuda'):
    model.eval()
    all_preds = []
    all_labels = []
    all_features = []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            outputs, features = model(x)
            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(y.numpy())
            all_features.append(features.cpu().numpy())
    all_features = np.concatenate(all_features)
    return np.array(all_preds), np.array(all_labels), all_features

def plot_accuracy(train_acc, val_acc, title='Accuracy'):
    plt.figure()
    plt.plot(train_acc, label='Train')
    plt.plot(val_acc, label='Validation')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title(title)
    plt.legend()
    plt.show()

def plot_confusion_matrix(y_true, y_pred, class_names, title='Confusion Matrix'):
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    # Set predicted axis (x-axis) labels vertically
    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')
    plt.title(title)
    plt.show()

def plot_decision_boundary(features, labels, model, device='cuda'):
    x_min, x_max = features[:,0].min() - 1, features[:,0].max() + 1
    y_min, y_max = features[:,1].min() - 1, features[:,1].max() + 1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))
    grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32).to(device)
    model.eval()
    with torch.no_grad():
        outputs = model.fc2(grid).cpu().numpy()
        Z = np.argmax(outputs, axis=1)
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, alpha=0.3)
    sns.scatterplot(x=features[:,0], y=features[:,1], hue=labels, palette='tab10', s=40)
    plt.title('Decision Boundary')
    plt.show()

# --- GRID SEARCH ---
def grid_search(model_class, train_dataset, val_dataset, test_loader, param_grid, device, save_path):
    best_acc = 0
    best_params = None
    best_state = None
    best_train_acc = None
    best_val_acc_list = None
    for lr in param_grid['lr']:
        for out_features in param_grid.get('out_features', [None]):
            print(f"{model_class.__name__}: lr={lr}" + (f", out_features={out_features}" if out_features else ""))
            if out_features:
                model = model_class(out_features=out_features).to(device)
            else:
                model = model_class().to(device)
            train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=64)
            train_acc, val_acc, state, best_val_acc = train_model(model, train_loader, val_loader, epochs=10, lr=lr, device=device)
            if best_val_acc > best_acc:
                best_acc = best_val_acc
                best_params = {'lr': lr}
                if out_features:
                    best_params['out_features'] = out_features
                best_state = copy.deepcopy(state)
                best_train_acc = train_acc
                best_val_acc_list = val_acc
    torch.save(best_state, save_path)
    np.save(save_path.replace('.pt', '_val_acc.npy'), best_val_acc_list)
    np.save(save_path.replace('.pt', '_train_acc.npy'), best_train_acc)
    print(f"Best params: {best_params}, best val acc: {best_acc:.4f}")
    print(f"Saved best model to {save_path}")
    # Test accuracy for best model
    if 'out_features' in best_params:
        model = model_class(out_features=best_params['out_features']).to(device)
    else:
        model = model_class().to(device)
    model.load_state_dict(torch.load(save_path))
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for x, y in test_loader:
            x, y = x.to(device), y.to(device)
            outputs, _ = model(x)
            _, preds = torch.max(outputs, 1)
            correct += (preds == y).sum().item()
            total += y.size(0)
    print(f"Test accuracy (best model): {correct/total:.4f}")
    return best_params, best_acc, save_path

# --- SPLIT DATA ---
device = 'cuda' if torch.cuda.is_available() else 'cpu'
batch_size = 64

# MNIST: split train into train/val
train_size = int(0.8 * len(mnist_train))
val_size = len(mnist_train) - train_size
mnist_train_split, mnist_val_split = random_split(mnist_train, [train_size, val_size])

# Imagenette: split train into train/val
train_size_img = int(0.8 * len(imagenette_train))
val_size_img = len(imagenette_train) - train_size_img
imagenette_train_split, imagenette_val_split = random_split(imagenette_train, [train_size_img, val_size_img])

mnist_test_loader = DataLoader(mnist_test, batch_size=batch_size)
imagenette_test_loader = DataLoader(imagenette_test, batch_size=batch_size)

# --- GRID SEARCH MNIST ---
print("\n===== GRID SEARCH MNIST - SimpleCNN =====")
param_grid_simple = {'lr': [0.01, 0.001, 0.0005], 'out_features': [64, 128, 256]}
best_params_simplecnn, best_acc_simplecnn, best_model_path_simplecnn = grid_search(
    SimpleCNN_MNIST, mnist_train_split, mnist_val_split, mnist_test_loader, param_grid_simple, device, 'best_SimpleCNN_MNIST.pt'
)

print("\n===== GRID SEARCH MNIST - TwoFeatureCNN =====")
param_grid_two = {'lr': [0.01, 0.001, 0.0005]}
best_params_twofeaturecnn, best_acc_twofeaturecnn, best_model_path_twofeaturecnn = grid_search(
    TwoFeatureCNN_MNIST, mnist_train_split, mnist_val_split, mnist_test_loader, param_grid_two, device, 'best_TwoFeatureCNN_MNIST.pt'
)

# --- GRID SEARCH IMAGENETTE ---
print("\n===== GRID SEARCH IMAGENETTE - SimpleCNN =====")
param_grid_simple_img = {'lr': [0.01, 0.001, 0.0005], 'out_features': [64, 128, 256]}
best_params_simplecnn_img, best_acc_simplecnn_img, best_model_path_simplecnn_img = grid_search(
    SimpleCNN_Imagenette, imagenette_train_split, imagenette_val_split, imagenette_test_loader, param_grid_simple_img, device, 'best_SimpleCNN_Imagenette.pt'
)

print("\n===== GRID SEARCH IMAGENETTE - TwoFeatureCNN =====")
param_grid_two_img = {'lr': [0.01, 0.001, 0.0005]}
best_params_twofeaturecnn_img, best_acc_twofeaturecnn_img, best_model_path_twofeaturecnn_img = grid_search(
    TwoFeatureCNN_Imagenette, imagenette_train_split, imagenette_val_split, imagenette_test_loader, param_grid_two_img, device, 'best_TwoFeatureCNN_Imagenette.pt'
)

# --- EWALUACJA WSZYSTKICH MODELI ---
def load_acc_history(model_path):
    val_acc = np.load(model_path.replace('.pt', '_val_acc.npy'))
    train_acc = np.load(model_path.replace('.pt', '_train_acc.npy'))
    return train_acc, val_acc

# MNIST - SimpleCNN
model = SimpleCNN_MNIST(out_features=best_params_simplecnn['out_features']).to(device)
model.load_state_dict(torch.load(best_model_path_simplecnn))
model.eval()
y_pred, y_true, features = get_predictions(model, mnist_test_loader, device=device)
plot_confusion_matrix(y_true, y_pred, class_names=[str(i) for i in range(10)], title='SimpleCNN MNIST Confusion Matrix')
train_acc, val_acc = load_acc_history(best_model_path_simplecnn)
plot_accuracy(train_acc, val_acc, title='SimpleCNN MNIST Accuracy')

# MNIST - TwoFeatureCNN
model2 = TwoFeatureCNN_MNIST().to(device)
model2.load_state_dict(torch.load(best_model_path_twofeaturecnn))
model2.eval()
y_pred2, y_true2, features2 = get_predictions(model2, mnist_test_loader, device=device)
plot_confusion_matrix(y_true2, y_pred2, class_names=[str(i) for i in range(10)], title='TwoFeatureCNN MNIST Confusion Matrix')
plot_decision_boundary(features2, y_true2, model2, device=device)
train_acc2, val_acc2 = load_acc_history(best_model_path_twofeaturecnn)
plot_accuracy(train_acc2, val_acc2, title='TwoFeatureCNN MNIST Accuracy')

# Imagenette - SimpleCNN
model3 = SimpleCNN_Imagenette(out_features=best_params_simplecnn_img['out_features']).to(device)
model3.load_state_dict(torch.load(best_model_path_simplecnn_img))
model3.eval()
y_pred3, y_true3, features3 = get_predictions(model3, imagenette_test_loader, device=device)
plot_confusion_matrix(y_true3, y_pred3, class_names=imagenette_train.classes, title='SimpleCNN Imagenette Confusion Matrix')
train_acc3, val_acc3 = load_acc_history(best_model_path_simplecnn_img)
plot_accuracy(train_acc3, val_acc3, title='SimpleCNN Imagenette Accuracy')

# Imagenette - TwoFeatureCNN
model4 = TwoFeatureCNN_Imagenette().to(device)
model4.load_state_dict(torch.load(best_model_path_twofeaturecnn_img))
model4.eval()
y_pred4, y_true4, features4 = get_predictions(model4, imagenette_test_loader, device=device)
plot_confusion_matrix(y_true4, y_pred4, class_names=imagenette_train.classes, title='TwoFeatureCNN Imagenette Confusion Matrix')
plot_decision_boundary(features4, y_true4, model4, device=device)
train_acc4, val_acc4 = load_acc_history(best_model_path_twofeaturecnn_img)
plot_accuracy(train_acc4, val_acc4, title='TwoFeatureCNN Imagenette Accuracy')

# Version 1 part 2
import os
# Upewnij się, że folder 'results' istnieje
if not os.path.exists('./results'):
    os.makedirs('./results')
# Upewnij się, że folder 'models' istnieje
if not os.path.exists('./models'):
    os.makedirs('./models')
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset, ConcatDataset, random_split
import numpy as np
import random
import matplotlib.pyplot as plt
import pandas as pd
from torchvision.datasets import MNIST, Imagenette
from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, RandomCrop, RandomHorizontalFlip, Resize
from PIL import Image
import copy
import os
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
batch_size = 64

# Model definitions (same as provided, assumed imported or copied here)
class SimpleCNN_MNIST(nn.Module):
    def __init__(self, out_features=128, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 16, 3, 1)
        self.conv2 = nn.Conv2d(16, 32, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(32*5*5, out_features)
        self.fc2 = nn.Linear(out_features, num_classes)
    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.pool(x)
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = torch.relu(self.fc1(x))
        out = self.fc2(features)
        return out, features

class TwoFeatureCNN_MNIST(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 8, 3, 1)
        self.conv2 = nn.Conv2d(8, 16, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(16*5*5, 2)
        self.fc2 = nn.Linear(2, num_classes)
    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.pool(x)
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = self.fc1(x)
        out = self.fc2(features)
        return out, features

class SimpleCNN_Imagenette(nn.Module):
    def __init__(self, out_features=128, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, 1)
        self.conv2 = nn.Conv2d(16, 32, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(32*14*14, out_features)
        self.fc2 = nn.Linear(out_features, num_classes)
    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.pool(x)
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = torch.relu(self.fc1(x))
        out = self.fc2(features)
        return out, features

class TwoFeatureCNN_Imagenette(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 8, 3, 1)
        self.conv2 = nn.Conv2d(8, 16, 3, 1)
        self.pool = nn.MaxPool2d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(16*14*14, 2)
        self.fc2 = nn.Linear(2, num_classes)
    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = self.pool(x)
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.flatten(x)
        features = self.fc1(x)
        out = self.fc2(features)
        return out, features

mnist_transform = Compose([
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])
mnist_aug1 = Compose([
    RandomRotation(10),
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])
mnist_aug2 = Compose([
    RandomRotation(20),
    RandomCrop(28, padding=2),
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])
imagenette_transform = Compose([
    Resize((64,64)),
    ToTensor(),
    Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])
imagenette_aug1 = Compose([
    Resize((64,64)),
    RandomHorizontalFlip(),
    RandomRotation(15),
    ToTensor(),
    Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])
imagenette_aug2 = Compose([
    Resize((64,64)),
    RandomHorizontalFlip(),
    RandomRotation(30),
    RandomCrop(64,padding=8),
    ToTensor(),
    Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

def set_seed(seed=42):
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)

def get_balanced_subset(dataset, n):
    if hasattr(dataset, 'targets'):
        targets = np.array(dataset.targets)
    elif hasattr(dataset, 'labels'):
        targets = np.array(dataset.labels)
    elif hasattr(dataset, 'samples'):
        targets = np.array([s[1] for s in dataset.samples])
    elif hasattr(dataset, '_samples'):
        targets = np.array([s[1] for s in dataset._samples])
    else:
        raise ValueError("Dataset does not have targets, labels, samples or _samples attribute")
    classes = np.unique(targets)
    n_per_class = n // len(classes)
    idxs = []
    for c in classes:
        class_idxs = np.where(targets == c)[0]
        chosen = np.random.choice(class_idxs, n_per_class, replace=False)
        idxs.extend(chosen)
    random.shuffle(idxs)
    return idxs

def create_train_dataset(full_dataset, size, augmentation_transform):
    if size == len(full_dataset):
        full_dataset.transform = augmentation_transform
        return full_dataset
    idxs = get_balanced_subset(full_dataset, size)
    subset = Subset(full_dataset, idxs)
    class TransformSubset(torch.utils.data.Dataset):
        def __init__(self, subset, transform):
            self.subset = subset
            self.transform = transform
        def __len__(self):
            return len(self.subset)
        def __getitem__(self, idx):
            x,y = self.subset[idx]
            if isinstance(x, torch.Tensor):
                return x,y
            else:
                return self.transform(x), y
    return TransformSubset(subset, augmentation_transform)

def train_model(model, train_loader, val_loader, epochs=10, lr=0.001, device='cuda'):
    model = model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()
    train_acc, val_acc = [], []
    best_val_acc = 0
    best_state = None
    for epoch in range(epochs):
        model.train()
        correct_train = 0
        total_train = 0
        for x,y in train_loader:
            x,y = x.to(device), y.to(device)
            optimizer.zero_grad()
            outputs, _ = model(x)
            loss = criterion(outputs,y)
            loss.backward()
            optimizer.step()
            _, preds = torch.max(outputs,1)
            correct_train += (preds==y).sum().item()
            total_train += y.size(0)
        train_epoch_acc = correct_train/total_train
        train_acc.append(train_epoch_acc)
        model.eval()
        correct_val = 0
        total_val = 0
        with torch.no_grad():
            for x,y in val_loader:
                x,y = x.to(device), y.to(device)
                outputs, _ = model(x)
                _, preds = torch.max(outputs,1)
                correct_val += (preds==y).sum().item()
                total_val += y.size(0)
        val_epoch_acc = correct_val/total_val
        val_acc.append(val_epoch_acc)
        if val_epoch_acc > best_val_acc:
            best_val_acc = val_epoch_acc
            best_state = copy.deepcopy(model.state_dict())
        print(f"Epoch {epoch+1}/{epochs} Train Acc={train_epoch_acc:.4f} Val Acc={val_epoch_acc:.4f}")
    return train_acc, val_acc, best_state, best_val_acc

def evaluate_model(model_class, train_dataset, val_dataset, test_dataset, epochs=10, lr=0.001, device=device):
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)
    test_loader = DataLoader(test_dataset, batch_size=batch_size)
    model = model_class().to(device)
    train_acc, val_acc, best_state, best_val_acc = train_model(model, train_loader, val_loader, epochs=epochs, lr=lr, device=device)
    model.load_state_dict(best_state)
    model.eval()
    correct = 0
    total = 0
    all_preds = []
    all_targets = []
    with torch.no_grad():
        for x,y in test_loader:
            x,y = x.to(device), y.to(device)
            out,_ = model(x)
            preds = out.argmax(1)
            correct += (preds==y).sum().item()
            total += y.size(0)
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(y.cpu().numpy())
    test_acc = correct/total
    return train_acc, val_acc, test_acc, best_state, all_preds, all_targets

def train_multiple_runs(model_class, train_dataset, val_dataset, test_dataset, epochs, runs=10, device=device):
    test_accuracies = []
    train_accs_all = []
    val_accs_all = []
    best_states = []
    all_preds = None
    all_targets = None
    for run in range(runs):
        print(f"Training run {run+1}/{runs}")
        train_acc, val_acc, test_acc, best_state, preds, targets = evaluate_model(
            model_class, train_dataset, val_dataset, test_dataset, epochs=epochs, device=device)
        test_accuracies.append(test_acc)
        train_accs_all.append(train_acc)
        val_accs_all.append(val_acc)
        best_states.append(best_state)
        # Store preds and targets from last run for confusion matrix (usually last run is representative)
        if run == runs - 1:
            all_preds = preds
            all_targets = targets
    mean_acc = np.mean(test_accuracies)
    std_acc = np.std(test_accuracies)
    print(f"Mean Test Accuracy over {runs} runs: {mean_acc:.4f}, Std: {std_acc:.4f}")
    return mean_acc, std_acc, best_states[-1], all_preds, all_targets, train_accs_all, val_accs_all

def plot_confusion_matrix(true_labels, pred_labels, classes, title='Macierz Pomyłek', save_path=None):
    cm = confusion_matrix(true_labels, pred_labels)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
    disp.plot(cmap='Blues')
    plt.title(title)
    plt.xticks(rotation=45)
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path)
        print(f'Saved confusion matrix to {save_path}')
    plt.show()

def plot_feature_distribution(model, data_loader, device, title, save_path=None):
    model.eval()
    features = []
    labels = []
    with torch.no_grad():
        for xb, yb in data_loader:
            xb = xb.to(device)
            _, feats = model(xb)
            features.append(feats.cpu().numpy())
            labels.append(yb.numpy())
    features = np.concatenate(features)
    labels = np.concatenate(labels)
    plt.figure(figsize=(7,7))
    sns.scatterplot(x=features[:,0], y=features[:,1], hue=labels, palette='tab10', s=40)
    plt.title(title)
    plt.legend(title='Klasa')
    if save_path:
        plt.savefig(save_path)
        print(f'Saved feature distribution plot to {save_path}')
    plt.show()

def plot_decision_boundaries(model, dataset, device, title, save_path=None, resolution=0.05):
    '''
    Plot decision boundaries for 2D features learned by 2-feature CNN.
    Dataset assumed balanced for better visualization.
    '''
    model.eval()
    loader = DataLoader(dataset, batch_size=batch_size)
    features = []
    labels = []
    with torch.no_grad():
        for xb, yb in loader:
            xb = xb.to(device)
            _, feats = model(xb)
            features.append(feats.cpu().numpy())
            labels.append(yb.numpy())
    features = np.concatenate(features)
    labels = np.concatenate(labels)

    x_min, x_max = features[:,0].min()-1, features[:,0].max()+1
    y_min, y_max = features[:,1].min()-1, features[:,1].max()+1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),
                         np.arange(y_min, y_max, resolution))
    mesh_points = np.c_[xx.ravel(), yy.ravel()]
    # Since model expects images, we cannot pass feature points; so we approximate decision boundary by training a simple classifier on features
    from sklearn.neighbors import KNeighborsClassifier
    clf = KNeighborsClassifier(n_neighbors=5)
    clf.fit(features, labels)
    Z = clf.predict(mesh_points)
    Z = Z.reshape(xx.shape)
    plt.figure(figsize=(8,8))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap='tab10')
    sns.scatterplot(x=features[:,0], y=features[:,1], hue=labels, palette='tab10', s=40, edgecolor='k')
    plt.title(title)
    plt.legend(title='Klasa')
    if save_path:
        plt.savefig(save_path)
        print(f'Saved decision boundaries plot to {save_path}')
    plt.show()

def run_multiple_training_experiments():
    # Define architectures, augmentations, data sizes for MNIST
    mnist_archs = {
        'SimpleCNN': SimpleCNN_MNIST,
        'TwoFeatureCNN': TwoFeatureCNN_MNIST
    }
    mnist_augmentations = {
        'brak': mnist_transform,
        'aug1': mnist_aug1,
        'aug2': mnist_aug2
    }
    mnist_data_sizes = [60000, 1000, 200, 100]  # ordered for tables as: all, 100, 200, 1000

    # Define architectures, augmentations, data sizes for Imagenette
    imagenette_archs = {
        'SimpleCNN': SimpleCNN_Imagenette,
      #  'TwoFeatureCNN': TwoFeatureCNN_Imagenette
    }
    imagenette_augmentations = {
        'brak': imagenette_transform,
        'aug1': imagenette_aug1,
        'aug2': imagenette_aug2
    }
    # Updated sizes here
    imagenette_data_sizes = [9469, 1000, 200, 100]

    # Load MNIST datasets
    mnist_train_full = MNIST(root='./data', train=True, download=True, transform=None)
    mnist_test = MNIST(root='./data', train=False, download=True, transform=mnist_transform)

    # Load Imagenette datasets
    imagenette_train_full = Imagenette(root='./data', split='train', download=True, transform=None)
    imagenette_test = Imagenette(root='./data', split='val', download=True, transform=imagenette_transform)


    # Results structure
    results = {}

    # Run experiments for MNIST
    for arch_name, arch_cls in mnist_archs.items():
        results[arch_name] = {}
        for aug_name, aug in mnist_augmentations.items():
            results[arch_name][aug_name] = {}
            for size in mnist_data_sizes:
                print(f"Running 10 trainings for MNIST {arch_name}, augmentation {aug_name}, data size {size}")
                train_dataset_full = create_train_dataset(mnist_train_full, size, aug)
                train_dataset, val_dataset = random_split(train_dataset_full, [int(0.8*len(train_dataset_full)), len(train_dataset_full)-int(0.8*len(train_dataset_full))])
                epochs = 10 if size >= 1000 else 20

                mean_acc, std_acc, best_state, preds, targets, train_accs, val_accs = train_multiple_runs(
                    arch_cls, train_dataset, val_dataset, mnist_test, epochs, runs=10, device=device)

                # Save results
                results[arch_name][aug_name][size] = {
                    'mean_acc': mean_acc,
                    'std_acc': std_acc,
                    'train_accs': train_accs,
                    'val_accs': val_accs,
                    'best_state': best_state,
                    'preds': preds,
                    'targets': targets
                }
                # Save model
                model_save_path = f'./models/mnist_{arch_name}_{aug_name}_{size}_10runs.pt'
                torch.save(best_state, model_save_path)
                print(f'Saved best model to {model_save_path}')

                # Save confusion matrix
                class_names = [str(i) for i in range(10)]
                cm_path = f'./results/cm_mnist_{arch_name}_{aug_name}_{size}.png'
                plot_confusion_matrix(targets, preds, classes=class_names,
                                      title=f'Matrix Pomyłek MNIST {arch_name} {aug_name} size {size}',
                                      save_path=cm_path)

                # For TwoFeatureCNN plot feature distribution and decision boundaries for train and test
                if 'TwoFeatureCNN' in arch_name:
                    train_loader = DataLoader(train_dataset, batch_size=batch_size)
                    test_loader = DataLoader(mnist_test, batch_size=batch_size)
                    model = arch_cls().to(device)
                    model.load_state_dict(best_state)
                    dist_train_path = f'./results/feat_dist_train_mnist_{arch_name}_{aug_name}_{size}.png'
                    dist_test_path = f'./results/feat_dist_test_mnist_{arch_name}_{aug_name}_{size}.png'
                    plot_feature_distribution(model, train_loader, device,
                                              title=f'Rozkład cech treningowych MNIST {arch_name} {aug_name} {size}',
                                              save_path=dist_train_path)
                    plot_feature_distribution(model, test_loader, device,
                                              title=f'Rozkład cech testowych MNIST {arch_name} {aug_name} {size}',
                                              save_path=dist_test_path)
                    # Decision boundaries on train data plot
                    db_path_train = f'./results/dec_bound_train_mnist_{arch_name}_{aug_name}_{size}.png'
                    plot_decision_boundaries(model, train_dataset, device,
                                             title=f'Granice decyzyjne trening MNIST {arch_name} {aug_name} {size}',
                                             save_path=db_path_train)

                    # Decision boundaries on test data plot
                    db_path_test = f'./results/dec_bound_test_mnist_{arch_name}_{aug_name}_{size}.png'
                    test_subset = Subset(mnist_test, range(min(1000, len(mnist_test))))
                    plot_decision_boundaries(model, test_subset, device,
                                             title=f'Granice decyzyjne test MNIST {arch_name} {aug_name} {size}',
                                             save_path=db_path_test)

    # Run experiments for Imagenette
    for arch_name, arch_cls in imagenette_archs.items():
        results[arch_name] = {}
        for aug_name, aug in imagenette_augmentations.items():
            results[arch_name][aug_name] = {}
            for size in imagenette_data_sizes:
                print(f"Running 10 trainings for Imagenette {arch_name}, augmentation {aug_name}, data size {size}")
                train_dataset_full = create_train_dataset(imagenette_train_full, size, aug)
                train_dataset, val_dataset = random_split(train_dataset_full, [int(0.8*len(train_dataset_full)), len(train_dataset_full)-int(0.8*len(train_dataset_full))])
                # Set epochs: 10 for largest, else 20
                epochs = 5 if size >= 1000 else 10

                mean_acc, std_acc, best_state, preds, targets, train_accs, val_accs = train_multiple_runs(
                    arch_cls, train_dataset, val_dataset, imagenette_test, epochs, runs=5, device=device)

                # Save results
                results[arch_name][aug_name][size] = {
                    'mean_acc': mean_acc,
                    'std_acc': std_acc,
                    'train_accs': train_accs,
                    'val_accs': val_accs,
                    'best_state': best_state,
                    'preds': preds,
                    'targets': targets
                }
                # Save model
                model_save_path = f'./models/imagenette_{arch_name}_{aug_name}_{size}_10runs.pt'
                torch.save(best_state, model_save_path)
                print(f'Saved best model to {model_save_path}')

                # Save confusion matrix
                class_names = ['tench', 'goldfish', 'great_white_shark', 'tiger_shark', 'hammerhead',
                               'electric_ray', 'stingray', 'cock', 'hen', 'ostrich']
                cm_path = f'./results/cm_imagenette_{arch_name}_{aug_name}_{size}.png'
                plot_confusion_matrix(targets, preds, classes=class_names,
                                      title=f'Matrix Pomyłek Imagenette {arch_name} {aug_name} size {size}',
                                      save_path=cm_path)

                # For TwoFeatureCNN plot feature distribution and decision boundaries for train and test
                if 'TwoFeatureCNN' in arch_name:
                    train_loader = DataLoader(train_dataset, batch_size=batch_size)
                    test_loader = DataLoader(imagenette_test, batch_size=batch_size)
                    model = arch_cls().to(device)
                    model.load_state_dict(best_state)
                    dist_train_path = f'./results/feat_dist_train_imagenette_{arch_name}_{aug_name}_{size}.png'
                    dist_test_path = f'./results/feat_dist_test_imagenette_{arch_name}_{aug_name}_{size}.png'
                    plot_feature_distribution(model, train_loader, device,
                                              title=f'Rozkład cech treningowych Imagenette {arch_name} {aug_name} {size}',
                                              save_path=dist_train_path)
                    plot_feature_distribution(model, test_loader, device,
                                              title=f'Rozkład cech testowych Imagenette {arch_name} {aug_name} {size}',
                                              save_path=dist_test_path)
                    # Decision boundaries on train data plot
                    db_path_train = f'./results/dec_bound_train_imagenette_{arch_name}_{aug_name}_{size}.png'
                    plot_decision_boundaries(model, train_dataset, device,
                                             title=f'Granice decyzyjne trening Imagenette {arch_name} {aug_name} {size}',
                                             save_path=db_path_train)

                    # Decision boundaries on test data plot
                    db_path_test = f'./results/dec_bound_test_imagenette_{arch_name}_{aug_name}_{size}.png'
                    test_subset = Subset(imagenette_test, range(min(1000, len(imagenette_test))))
                    plot_decision_boundaries(model, test_subset, device,
                                             title=f'Granice decyzyjne test Imagenette {arch_name} {aug_name} {size}',
                                             save_path=db_path_test)

    return results

def generate_report_tables_and_examples(results, arch_names, augment_names, data_sizes, imagenette_data_sizes):

    # Generate tables mean&std acc for MNIST
    for arch_name in arch_names:
        print(f"\n***** Results for architecture: {arch_name} *****")
        rows = []
        for aug_name in augment_names:
            row = []
            for size in data_sizes:
                res = results[arch_name][aug_name][size]
                mean_acc = res['mean_acc']
                std_acc = res['std_acc']
                row.append(f"{mean_acc:.4f} ± {std_acc:.4f}")
            rows.append(row)
        df = pd.DataFrame(rows, index=augment_names, columns=[str(s) for s in data_sizes])
        print(df)
        display(df)

    # Generate tables mean&std acc for Imagenette
    for arch_name in arch_names:
        if arch_name in results:  # Check if architecture exists in results
            print(f"\n***** Results for architecture: {arch_name} (Imagenette) *****")
            rows = []
            for aug_name in augment_names:
                row = []
                for size in imagenette_data_sizes:
                    res = results[arch_name][aug_name][size]
                    mean_acc = res['mean_acc']
                    std_acc = res['std_acc']
                    row.append(f"{mean_acc:.4f} ± {std_acc:.4f}")
                rows.append(row)
            df = pd.DataFrame(rows, index=augment_names, columns=[str(s) for s in imagenette_data_sizes])
            print(df)
            display(df)

def main():
    set_seed(42)
    # Run multiple runs experiment (pages 5 and 7)
    results = run_multiple_training_experiments()

    arch_names = ['SimpleCNN']
    augmentation_names = ['brak', 'aug1', 'aug2']
    data_sizes = [60000, 1000, 200, 100]
    imagenette_data_sizes = [9469, 1000, 200, 100]  # Sizes for Imagenette

    # Print summary tables and examples
    generate_report_tables_and_examples(results, arch_names, augmentation_names, data_sizes, imagenette_data_sizes)

if __name__=="__main__":
    main()

# Pokaz obrazki i przeksztalcenia
import os
import matplotlib.pyplot as plt
import numpy as np
from torchvision.datasets import MNIST, Imagenette
from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, RandomCrop, RandomHorizontalFlip, Resize
from PIL import Image

# Define transformations for MNIST
mnist_transform = Compose([
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])
mnist_aug1 = Compose([
    RandomRotation(10),
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])
mnist_aug2 = Compose([
    RandomRotation(20),
    RandomCrop(28, padding=2),
    ToTensor(),
    Normalize((0.1307,), (0.3081,))
])

# Define transformations for Imagenette
imagenette_transform = Compose([
    Resize((64, 64)),
    ToTensor(),
    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
imagenette_aug1 = Compose([
    Resize((64, 64)),
    RandomHorizontalFlip(),
    RandomRotation(15),
    ToTensor(),
    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
imagenette_aug2 = Compose([
    Resize((64, 64)),
    RandomHorizontalFlip(),
    RandomRotation(30),
    RandomCrop(64, padding=8),
    ToTensor(),
    Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def show_augmentation_examples(dataset, transform, n=5, is_rgb=False, save_path_prefix=None):
    fig, axs = plt.subplots(2, n, figsize=(2*n, 4))
    for i in range(n):
        img, label = dataset[i]

        # If the image is a PIL Image, convert it to a tensor for augmentation
        if isinstance(img, Image.Image):
            img_tensor = ToTensor()(img)  # Convert PIL Image to tensor
        else:
            img_tensor = img  # If it's already a tensor, use it directly

        axs[0, i].imshow(img_tensor.permute(1, 2, 0) if is_rgb else img_tensor.squeeze(), cmap=None if is_rgb else 'gray')
        axs[0, i].set_title(f'Oryginalny {label}')
        axs[0, i].axis('off')

        # Apply augmentation
        img_aug = transform(img) if isinstance(img, Image.Image) else transform(img_tensor)  # Apply the transformation

        axs[1, i].imshow(img_aug.permute(1, 2, 0) if is_rgb else img_aug.squeeze(), cmap=None if is_rgb else 'gray')
        axs[1, i].set_title('Po augmentacji')
        axs[1, i].axis('off')

    plt.tight_layout()
    if save_path_prefix:
        plt.savefig(save_path_prefix + '.png')
        print(f'Saved augmentation examples to {save_path_prefix}.png')
    plt.show()

# Load MNIST dataset
mnist_train_full = MNIST(root='./data', train=True, download=True, transform=None)

# Show augmentation examples for MNIST
for aug_name, aug_transform in zip(['brak', 'aug1', 'aug2'], [mnist_transform, mnist_aug1, mnist_aug2]):
    print(f"Augmentation examples for MNIST: {aug_name}")
    show_augmentation_examples(mnist_train_full, aug_transform, n=5, is_rgb=False,
                               save_path_prefix=f'./results/aug_examples_mnist_{aug_name}')

# Load Imagenette dataset
imagenette_train_full = Imagenette(root='./data', split='train', download=True, transform=None)

# Show augmentation examples for Imagenette
for aug_name, aug_transform in zip(['brak', 'aug1', 'aug2'], [imagenette_transform, imagenette_aug1, imagenette_aug2]):
    print(f"Augmentation examples for Imagenette: {aug_name}")
    show_augmentation_examples(imagenette_train_full, aug_transform, n=5, is_rgb=True,
                               save_path_prefix=f'./results/aug_examples_imagenette_{aug_name}')

